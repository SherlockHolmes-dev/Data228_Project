{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/anaconda3/envs/naturalistvenv/lib/python3.12/site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/anaconda3/envs/naturalistvenv/lib/python3.12/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/naturalistvenv/lib/python3.12/site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "load_dotenv(\"azure_connection.env\")\n",
    "\n",
    "storage_account_name = os.getenv(\"AZURE_ACCOUNT_NAME\")\n",
    "storage_account_key = os.getenv(\"AZURE_STORAGE_KEY\")\n",
    "storage_container_name = \"kaggle-datasets\"\n",
    "parquet_blob_name = \"github-dataset-full.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/anaconda3/envs/naturalistvenv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/matthewleffler/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/matthewleffler/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-azure added as a dependency\n",
      "com.microsoft.azure#azure-storage added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9c21c555-cf9f-450f-afda-bedea1317f68;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-azure;3.3.2 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in local-m2-cache\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in local-m2-cache\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in local-m2-cache\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.43.v20210629 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound com.microsoft.azure#azure-storage;8.6.6 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.9.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.12 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.4 in central\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.2.4 in central\n",
      "\tfound com.google.guava#guava;24.1.1-jre in central\n",
      "\tfound com.google.code.findbugs#jsr305;1.3.9 in local-m2-cache\n",
      "\tfound org.checkerframework#checker-compat-qual;2.0.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.1.3 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in local-m2-cache\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.14 in central\n",
      ":: resolution report :: resolve 938ms :: artifacts dl 41ms\n",
      "\t:: modules in use:\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.9.4 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;1.3.9 from local-m2-cache in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.1.3 from central in [default]\n",
      "\tcom.google.guava#guava;24.1.1-jre from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from local-m2-cache in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.2.4 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;8.6.6 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from local-m2-cache in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from local-m2-cache in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from local-m2-cache in [default]\n",
      "\torg.checkerframework#checker-compat-qual;2.0.0 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.14 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.43.v20210629 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.12 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 by [com.microsoft.azure#azure-storage;8.6.6] in [default]\n",
      "\torg.apache.commons#commons-lang3;3.8.1 by [org.apache.commons#commons-lang3;3.4] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   24  |   0   |   0   |   2   ||   22  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9c21c555-cf9f-450f-afda-bedea1317f68\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 22 already retrieved (0kB/20ms)\n",
      "25/04/27 17:26:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Creating Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read Parquet from Azure Blob Storage\") \\\n",
    "    .config(\"spark.hadoop.fs.azure.account.key.<your-storage-account>.blob.core.windows.net\", storage_account_key) \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-azure:3.3.2,com.microsoft.azure:azure-storage:8.6.6\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Remove garbage error texts\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: (Optional) Set Hadoop configurations if not already set during builder\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\",\n",
    "    storage_account_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define path to the Parquet\n",
    "parquet_path = f\"wasbs://{storage_container_name}@{storage_account_name}.blob.core.windows.net/{parquet_blob_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, BooleanType, ArrayType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"bio\", StringType(), True),\n",
    "    StructField(\"blog\", StringType(), True),\n",
    "    StructField(\"commit_list\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"author_id\", LongType(), True),\n",
    "            StructField(\"commit_at\", StringType(), True),\n",
    "            StructField(\"committer_id\", LongType(), True),\n",
    "            StructField(\"generate_at\", StringType(), True),\n",
    "            StructField(\"message\", StringType(), True),\n",
    "            StructField(\"repo_description\", StringType(), True),\n",
    "            StructField(\"repo_id\", LongType(), True),\n",
    "            StructField(\"repo_name\", StringType(), True),\n",
    "            StructField(\"repo_owner_id\", LongType(), True)\n",
    "        ])\n",
    "    ), True),\n",
    "    StructField(\"commits\", LongType(), True),\n",
    "    StructField(\"company\", StringType(), True),\n",
    "    StructField(\"created_at\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"follower_list\", ArrayType(LongType(), True), True),\n",
    "    StructField(\"followers\", LongType(), True),\n",
    "    StructField(\"following\", LongType(), True),\n",
    "    StructField(\"following_list\", ArrayType(LongType(), True), True),\n",
    "    StructField(\"hirable\", BooleanType(), True),\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"is_suspicious\", BooleanType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"login\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"public_gists\", LongType(), True),\n",
    "    StructField(\"public_repos\", LongType(), True),\n",
    "    StructField(\"repo_list\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"created_at\", StringType(), True),\n",
    "            StructField(\"default_branch\", StringType(), True),\n",
    "            StructField(\"description\", StringType(), True),\n",
    "            StructField(\"fork\", BooleanType(), True),\n",
    "            StructField(\"forks_count\", LongType(), True),\n",
    "            StructField(\"full_name\", StringType(), True),\n",
    "            StructField(\"has_wiki\", BooleanType(), True),\n",
    "            StructField(\"id\", LongType(), True),\n",
    "            StructField(\"language\", StringType(), True),\n",
    "            StructField(\"license\", StringType(), True),\n",
    "            StructField(\"open_issues\", LongType(), True),\n",
    "            StructField(\"owner_id\", LongType(), True),\n",
    "            StructField(\"pushed_at\", StringType(), True),\n",
    "            StructField(\"size\", LongType(), True),\n",
    "            StructField(\"stargazers_count\", LongType(), True),\n",
    "            StructField(\"updated_at\", StringType(), True)\n",
    "        ])\n",
    "    ), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"updated_at\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bio: string (nullable = true)\n",
      " |-- blog: string (nullable = true)\n",
      " |-- commit_list: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- author_id: long (nullable = true)\n",
      " |    |    |-- commit_at: string (nullable = true)\n",
      " |    |    |-- committer_id: long (nullable = true)\n",
      " |    |    |-- generate_at: string (nullable = true)\n",
      " |    |    |-- message: string (nullable = true)\n",
      " |    |    |-- repo_description: string (nullable = true)\n",
      " |    |    |-- repo_id: long (nullable = true)\n",
      " |    |    |-- repo_name: string (nullable = true)\n",
      " |    |    |-- repo_owner_id: long (nullable = true)\n",
      " |-- commits: long (nullable = true)\n",
      " |-- company: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- follower_list: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- followers: long (nullable = true)\n",
      " |-- following: long (nullable = true)\n",
      " |-- following_list: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- hirable: boolean (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- is_suspicious: boolean (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- login: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- public_gists: long (nullable = true)\n",
      " |-- public_repos: long (nullable = true)\n",
      " |-- repo_list: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- default_branch: string (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- fork: boolean (nullable = true)\n",
      " |    |    |-- forks_count: long (nullable = true)\n",
      " |    |    |-- full_name: string (nullable = true)\n",
      " |    |    |-- has_wiki: boolean (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- language: string (nullable = true)\n",
      " |    |    |-- license: string (nullable = true)\n",
      " |    |    |-- open_issues: long (nullable = true)\n",
      " |    |    |-- owner_id: long (nullable = true)\n",
      " |    |    |-- pushed_at: string (nullable = true)\n",
      " |    |    |-- size: long (nullable = true)\n",
      " |    |    |-- stargazers_count: long (nullable = true)\n",
      " |    |    |-- updated_at: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- updated_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Read the Parquet file\n",
    "df = spark.read.schema(schema).parquet(parquet_path)\n",
    "\n",
    "# Step 6: Preview\n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (naturalistvenv)",
   "language": "python",
   "name": "naturalistvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
