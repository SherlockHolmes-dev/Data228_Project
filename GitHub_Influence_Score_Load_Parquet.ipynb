{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK6CZeX9vMV-",
        "outputId": "a045a18e-6c02-496b-8599-968acfff12b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ],
      "metadata": {
        "id": "eqm2htZ5vSe8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables\n",
        "from google.colab import userdata\n",
        "\n",
        "load_dotenv(\"azure_connection.env\")\n",
        "\n",
        "storage_account_name = userdata.get('AZURE_ACCOUNT_NAME')\n",
        "storage_account_key = userdata.get('AZURE_STORAGE_KEY')\n",
        "storage_container_name = \"kaggle-datasets\"\n",
        "parquet_blob_name = \"github-dataset-full.parquet\""
      ],
      "metadata": {
        "id": "mHFaNuAOvYtt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Read Parquet from Azure Blob Storage\") \\\n",
        "    .config(f\"spark.hadoop.fs.azure.account.key.{storage_account_name}.blob.core.windows.net\", storage_account_key) \\\n",
        "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-azure:3.3.2,com.microsoft.azure:azure-storage:8.6.6\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Remove garbage error texts\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")"
      ],
      "metadata": {
        "id": "GJB9Ob4nvrDF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: (Optional) Set Hadoop configurations if not already set during builder\n",
        "spark.conf.set(\n",
        "    f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\",\n",
        "    storage_account_key\n",
        ")"
      ],
      "metadata": {
        "id": "iJc1gH3DwTEb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Read parquet file spliited based on non-nesting\n",
        "non_list_df = spark.read.parquet(\n",
        "    \"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/clean_data/non_list_data\"\n",
        ")\n",
        "\n",
        "# Ensure data was saved\n",
        "non_list_df.show(10, truncate=False)"
      ],
      "metadata": {
        "id": "rjoUdoZTE-su",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159c6cd6-b90d-4e48-d275-90268dcd28f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------------+-------+----------+-------------------+-----+---------+---------+-------+--------+-------------+--------+----------------------+-----------+------------+------------+----+-------------------+\n",
            "|bio |blog            |commits|company   |created_at         |email|followers|following|hirable|id      |is_suspicious|location|login                 |name       |public_gists|public_repos|type|updated_at         |\n",
            "+----+----------------+-------+----------+-------------------+-----+---------+---------+-------+--------+-------------+--------+----------------------+-----------+------------+------------+----+-------------------+\n",
            "|NULL|                |NULL   |NULL      |2015-09-21 02:52:29|NULL |0        |0        |NULL   |14413602|true         |NULL    |llciq992              |NULL       |0           |0           |User|2016-02-28 18:26:34|\n",
            "|NULL|                |0      |NULL      |2014-10-05 17:46:27|NULL |0        |0        |NULL   |9025223 |false        |NULL    |cymssss45             |NULL       |0           |0           |User|2018-01-12 04:46:57|\n",
            "|NULL|                |NULL   |NULL      |2016-03-04 06:29:01|NULL |0        |0        |NULL   |17626302|true         |NULL    |borders145704414125821|NULL       |0           |0           |User|2016-03-04 06:29:02|\n",
            "|NULL|                |0      |NULL      |2016-01-24 14:07:38|NULL |0        |0        |NULL   |16860856|false        |NULL    |chiaotzu              |NULL       |0           |1           |User|2016-01-24 14:07:38|\n",
            "|NULL|                |9      |NULL      |2015-11-12 05:07:45|NULL |0        |0        |NULL   |15806633|false        |NULL    |gabriel793            |NULL       |1           |13          |User|2017-01-21 07:09:13|\n",
            "|NULL|                |1      |NULL      |2011-10-25 23:45:52|NULL |0        |0        |NULL   |1151203 |false        |NULL    |Biagio                |NULL       |0           |2           |User|2017-10-12 07:30:45|\n",
            "|CTO |http://canya.com|59     |CanYa Inc.|2009-10-18 15:47:51|NULL |33       |146      |true   |141210  |false        |MÃ¡laga  |jlsuarezs             |Juan Suarez|69          |473         |User|2018-05-02 07:25:38|\n",
            "|NULL|                |0      |NULL      |2016-01-13 22:30:20|NULL |0        |0        |NULL   |16686692|false        |NULL    |szp9177               |NULL       |0           |1           |User|2016-12-07 14:54:37|\n",
            "|NULL|                |NULL   |NULL      |2016-05-01 23:34:22|NULL |0        |0        |NULL   |18952046|true         |NULL    |ixoxek                |NULL       |0           |1           |User|2016-05-02 07:30:43|\n",
            "|NULL|                |0      |NULL      |2014-03-13 01:10:21|NULL |0        |0        |NULL   |6932921 |false        |NULL    |joellerosen           |NULL       |0           |0           |User|2016-02-27 22:40:43|\n",
            "+----+----------------+-------+----------+-------------------+-----+---------+---------+-------+--------+-------------+--------+----------------------+-----------+------------+------------+----+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Read parquet file spliited based on nesting\n",
        "\n",
        "# Read data to ensure data was properly saved\n",
        "repo_list_df = spark.read.parquet(\n",
        "    \"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/clean_data/repo_list_data\"\n",
        ")\n",
        "\n",
        "# Read data to ensure data was properly saved\n",
        "following_list_df = spark.read.parquet(\n",
        "    \"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/clean_data/following_list_data\"\n",
        ")\n",
        "\n",
        "# Read data to ensure data was properly saved\n",
        "follower_list_df = spark.read.parquet(\n",
        "    \"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/clean_data/follower_list_data\"\n",
        ")\n",
        "\n",
        "\n",
        "# Read data to ensure data was properly saved\n",
        "commit_list_df = spark.read.parquet(\n",
        "    \"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/clean_data/commit_list_data\"\n",
        ")"
      ],
      "metadata": {
        "id": "PKT8CQQJBmk3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# 1. Compute follower counts per user\n",
        "followers_agg = (\n",
        "    follower_list_df\n",
        "    .groupBy(\"user_id\", \"user_login\")\n",
        "    .agg(F.count(\"*\").alias(\"follower_count\"))\n",
        ")\n",
        "\n",
        "# 2. Compute total stargazers per user\n",
        "stars_agg = (\n",
        "    repo_list_df\n",
        "    .groupBy(\"user_id\", \"user_login\")\n",
        "    .agg(F.sum(\"repo_stargazers_count\").alias(\"total_stars\"))\n",
        ")\n",
        "\n",
        "# 3. Compute total commits per user\n",
        "commits_agg = (\n",
        "    commit_list_df\n",
        "    .groupBy(\"user_id\", \"user_login\")\n",
        "    .agg(F.count(\"*\").alias(\"total_commits\"))\n",
        ")\n",
        "\n",
        "# 4. Compute total forks per user\n",
        "forks_agg = (\n",
        "    repo_list_df\n",
        "    .groupBy(\"user_id\", \"user_login\")\n",
        "    .agg(F.sum(\"repo_forks_count\").alias(\"total_forks\"))\n",
        ")\n",
        "\n",
        "# 5. Join all aggregates together\n",
        "influence_df = (\n",
        "    followers_agg\n",
        "    .join(stars_agg,   on=[\"user_id\",\"user_login\"], how=\"full_outer\")\n",
        "    .join(commits_agg, on=[\"user_id\",\"user_login\"], how=\"full_outer\")\n",
        "    .join(forks_agg,   on=[\"user_id\",\"user_login\"], how=\"full_outer\")\n",
        "    .na.fill(0, [\"follower_count\", \"total_stars\", \"total_commits\", \"total_forks\"])\n",
        ")\n"
      ],
      "metadata": {
        "id": "p0wh5v5mBxFn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 6. Compute a weighted influence score\n",
        "#    Adjust weights as you see fit. Example weights:\n",
        "#      followers: 40%, stars: 25%, forks: 20%, commits: 15%\n",
        "influence_df = influence_df.withColumn(\n",
        "    \"influence_score\",\n",
        "    0.4   * F.col(\"follower_count\") +\n",
        "    0.25  * F.col(\"total_stars\")    +\n",
        "    0.20  * F.col(\"total_forks\")    +\n",
        "    0.15  * F.col(\"total_commits\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "hkKtpLQkEkOW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Get Top N developers by influence\n",
        "top_developers = (\n",
        "    influence_df\n",
        "    .orderBy(F.col(\"influence_score\").desc())\n",
        "    .limit(100)\n",
        ")\n",
        "\n",
        "# 8. Inspect or persist results\n",
        "top_developers.show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w1iv10HEl-7",
        "outputId": "2e19e293-9f46-4016-93be-fa361d8ebe90"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+--------------+-----------+-------------+-----------+------------------+\n",
            "|user_id |user_login |follower_count|total_stars|total_commits|total_forks|influence_score   |\n",
            "+--------+-----------+--------------+-----------+-------------+-----------+------------------+\n",
            "|6154722 |Microsoft  |0             |415789     |0            |103979     |124743.05         |\n",
            "|6128107 |vuejs      |0             |243181     |0            |41423      |69079.85          |\n",
            "|82592   |square     |2             |205975     |0            |36317      |58757.950000000004|\n",
            "|18461506|Tencent    |0             |149961     |0            |33305      |44151.25          |\n",
            "|3006190 |shadowsocks|0             |125507     |0            |61991      |43774.95          |\n",
            "|1136800 |h5bp       |3             |110190     |0            |22505      |32049.7           |\n",
            "|10639145|apple      |0             |99580      |1            |14436      |27782.350000000002|\n",
            "|1562726 |d3         |0             |91227      |0            |23043      |27415.35          |\n",
            "|958072  |laravel    |0             |85821      |0            |28099      |27075.05          |\n",
            "|6407041 |ReactiveX  |0             |93824      |0            |14002      |26256.4           |\n",
            "+--------+-----------+--------------+-----------+-------------+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "influence_df\\\n",
        "  .repartition(10) \\\n",
        "  .write \\\n",
        "  .mode(\"overwrite\") \\\n",
        "  .parquet(\"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/clean_data/Influence_Full_Data\")\n",
        "\n",
        "# 2. Persist just the Top-10\n",
        "top_developers \\\n",
        "  .coalesce(1) \\\n",
        "  .write \\\n",
        "  .mode(\"overwrite\") \\\n",
        "  .parquet(\"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/clean_data/Influence_Top\")"
      ],
      "metadata": {
        "id": "wFbfJL0vH-qZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Read parquet file spliited based on non-nesting\n",
        "non_list_df = spark.read.parquet(\n",
        "    \"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/clean_data/Influence_Full_Data\"\n",
        ")\n",
        "\n",
        "# Ensure data was saved\n",
        "non_list_df.show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx7qtVcPLxy-",
        "outputId": "808f07ae-5305-4b40-e9a9-cc77f2573bf8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+--------------+-----------+-------------+-----------+------------------+\n",
            "|user_id |user_login |follower_count|total_stars|total_commits|total_forks|influence_score   |\n",
            "+--------+-----------+--------------+-----------+-------------+-----------+------------------+\n",
            "|13896627|zhichisobot|0             |1          |109          |1          |16.799999999999997|\n",
            "|488516  |bezgail    |1             |0          |55           |0          |8.65              |\n",
            "|23394522|kskmurari  |0             |0          |0            |0          |0.0               |\n",
            "|14363952|abhishek486|0             |0          |7            |0          |1.05              |\n",
            "|14271264|ybolin     |0             |0          |2            |0          |0.3               |\n",
            "|29147019|MrRein     |0             |0          |1            |0          |0.15              |\n",
            "|17780779|abeaugrand |0             |0          |0            |0          |0.0               |\n",
            "|16071143|ela4ka     |2             |0          |18           |0          |3.5               |\n",
            "|19959601|tbruner    |0             |0          |22           |0          |3.3               |\n",
            "|7946771 |ipique     |0             |0          |2            |0          |0.3               |\n",
            "+--------+-----------+--------------+-----------+-------------+-----------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Read parquet file spliited based on non-nesting\n",
        "non_list_df = spark.read.parquet(\n",
        "    \"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/clean_data/Influence_Top\"\n",
        ")\n",
        "\n",
        "# Ensure data was saved\n",
        "non_list_df.show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCZSnfj6L11h",
        "outputId": "84c099d1-e39a-4908-ff50-2f72b9208636"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+--------------+-----------+-------------+-----------+------------------+\n",
            "|user_id |user_login |follower_count|total_stars|total_commits|total_forks|influence_score   |\n",
            "+--------+-----------+--------------+-----------+-------------+-----------+------------------+\n",
            "|6154722 |Microsoft  |0             |415789     |0            |103979     |124743.05         |\n",
            "|6128107 |vuejs      |0             |243181     |0            |41423      |69079.85          |\n",
            "|82592   |square     |2             |205975     |0            |36317      |58757.950000000004|\n",
            "|18461506|Tencent    |0             |149961     |0            |33305      |44151.25          |\n",
            "|3006190 |shadowsocks|0             |125507     |0            |61991      |43774.95          |\n",
            "|1136800 |h5bp       |3             |110190     |0            |22505      |32049.7           |\n",
            "|10639145|apple      |0             |99580      |1            |14436      |27782.350000000002|\n",
            "|1562726 |d3         |0             |91227      |0            |23043      |27415.35          |\n",
            "|958072  |laravel    |0             |85821      |0            |28099      |27075.05          |\n",
            "|6407041 |ReactiveX  |0             |93824      |0            |14002      |26256.4           |\n",
            "+--------+-----------+--------------+-----------+-------------+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}