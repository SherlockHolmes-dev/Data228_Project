{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/anaconda3/envs/naturalistvenv/lib/python3.12/site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/anaconda3/envs/naturalistvenv/lib/python3.12/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/naturalistvenv/lib/python3.12/site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install pyspark\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pyspark.sql.functions import explode, col, to_timestamp, substring\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, BooleanType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables for Azure access information\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "storage_account_name = os.getenv(\"AZURE_ACCOUNT_NAME\")\n",
    "storage_account_key = os.getenv(\"AZURE_STORAGE_KEY\")\n",
    "storage_container_name = \"kaggle-datasets\"\n",
    "parquet_blob_name = \"github-dataset-full.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/anaconda3/envs/naturalistvenv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/matthewleffler/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/matthewleffler/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-azure added as a dependency\n",
      "com.microsoft.azure#azure-storage added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-46248f3d-8851-4247-b9b1-e304457cc47a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-azure;3.3.2 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in local-m2-cache\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in local-m2-cache\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in local-m2-cache\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.43.v20210629 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound com.microsoft.azure#azure-storage;8.6.6 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.9.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.12 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.4 in central\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.2.4 in central\n",
      "\tfound com.google.guava#guava;24.1.1-jre in central\n",
      "\tfound com.google.code.findbugs#jsr305;1.3.9 in local-m2-cache\n",
      "\tfound org.checkerframework#checker-compat-qual;2.0.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.1.3 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in local-m2-cache\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.14 in central\n",
      ":: resolution report :: resolve 206ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.9.4 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;1.3.9 from local-m2-cache in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.1.3 from central in [default]\n",
      "\tcom.google.guava#guava;24.1.1-jre from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from local-m2-cache in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.2.4 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;8.6.6 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from local-m2-cache in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from local-m2-cache in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from local-m2-cache in [default]\n",
      "\torg.checkerframework#checker-compat-qual;2.0.0 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.14 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.43.v20210629 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.12 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 by [com.microsoft.azure#azure-storage;8.6.6] in [default]\n",
      "\torg.apache.commons#commons-lang3;3.8.1 by [org.apache.commons#commons-lang3;3.4] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   24  |   0   |   0   |   2   ||   22  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-46248f3d-8851-4247-b9b1-e304457cc47a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 22 already retrieved (0kB/6ms)\n",
      "25/05/06 11:37:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Creating Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read Parquet from Azure Blob Storage\") \\\n",
    "    .config(f\"spark.hadoop.fs.azure.account.key.{storage_account_name}.blob.core.windows.net\", storage_account_key) \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-azure:3.3.2,com.microsoft.azure:azure-storage:8.6.6\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Remove garbage error texts\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set authentification for Spark to connect to Azure\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\",\n",
    "    storage_account_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Repo List Data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data to ensure data was properly saved\n",
    "repo_list_df = spark.read.parquet(\n",
    "    \"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/clean_data/repo_list_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-------------------+-------------------+--------------------+---------+----------------+--------------------+-------------+---------+-------------+--------------------+----------------+-------------+-------------------+---------+---------------------+-------------------+\n",
      "| user_id|  user_login|    repo_created_at|repo_default_branch|    repo_description|repo_fork|repo_forks_count|      repo_full_name|repo_has_wiki|  repo_id|repo_language|        repo_license|repo_open_issues|repo_owner_id|     repo_pushed_at|repo_size|repo_stargazers_count|    repo_updated_at|\n",
      "+--------+------------+-------------------+-------------------+--------------------+---------+----------------+--------------------+-------------+---------+-------------+--------------------+----------------+-------------+-------------------+---------+---------------------+-------------------+\n",
      "|  323831|      cynial|2014-10-14 06:16:37|             master|Ace (Ajax.org Clo...|     true|               0|          cynial/ace|         true| 25192765|         NULL|               Other|               0|       323831|2014-10-11 15:42:18|    30609|                    0|2014-10-14 06:15:17|\n",
      "|  323831|      cynial|2012-10-16 07:26:47|             master|A jQuery Slider p...|     true|               0|cynial/AnythingSl...|         true|  6240492|   JavaScript|GNU Lesser Genera...|               0|       323831|2012-08-27 18:08:37|     2422|                    0|2013-01-12 16:51:11|\n",
      "|  323831|      cynial|2015-06-10 01:13:49|             master|A web interface f...|     true|               0|     cynial/dockerui|         true| 37167865|   JavaScript|               Other|               0|       323831|2015-06-05 15:23:33|    16539|                    0|2016-04-19 22:11:35|\n",
      "|  323831|      cynial|2015-06-24 03:16:11|             master|A structured logg...|     true|               0|cynial/fluent-log...|         true| 37959473|         Java|  Apache License 2.0|               0|       323831|2015-06-21 12:33:59|      650|                    0|2015-06-24 03:16:12|\n",
      "|  323831|      cynial|2013-04-11 16:04:18|             master|jQuery and Wordpr...|     true|               0|cynial/infinite-s...|         true|  9374439|   JavaScript|                NULL|               0|       323831|2013-03-22 20:19:26|     4439|                    0|2015-02-20 03:14:06|\n",
      "|  323831|      cynial|2012-11-02 02:34:05|             master|jQuery ScrollTo -...|     true|               0|cynial/jquery-scr...|         true|  6500382|   JavaScript|         MIT License|               0|       323831|2012-10-21 04:14:18|      255|                    0|2014-02-24 23:22:49|\n",
      "|  323831|      cynial|2013-04-14 13:33:30|             master|Laravel 4 Starter...|     true|               0|cynial/Laravel-4-...|         true|  9429412|   JavaScript|                NULL|               0|       323831|2013-04-11 00:34:45|      610|                    0|2014-04-12 16:37:47|\n",
      "|  323831|      cynial|2013-03-17 09:10:05|             master|                NULL|     true|               0|cynial/laravel-tu...|         true|  8832168|          PHP|               Other|               0|       323831|2012-10-15 15:59:43|      842|                    0|2013-03-17 09:10:05|\n",
      "|  323831|      cynial|2014-09-01 01:40:33|             master|Lithium is a ligh...|     true|               0|      cynial/lithium|         true| 23527330|         NULL|BSD 3-Clause \"New...|               0|       323831|2014-08-30 18:10:08|    16750|                    0|2014-09-01 01:37:03|\n",
      "|  323831|      cynial|2016-04-14 11:00:51|             master|A minimalistic ad...|    false|               0|cynial/logspout-l...|         true| 56230319|           Go|                NULL|               0|       323831|2016-04-15 01:46:33|        2|                    0|2016-04-14 11:09:17|\n",
      "|  323831|      cynial|2017-09-29 16:04:56|             master|Integrates Marath...|     true|               0|cynial/marathon-c...|         true|105291810|           Go|  Apache License 2.0|               0|       323831|2017-09-30 02:26:26|    15177|                    0|2017-09-29 16:04:59|\n",
      "|  323831|      cynial|2012-05-03 15:27:39|             master|STBlog base on Co...|    false|              20|       cynial/STBlog|         true|  4215382|          PHP|               Other|               0|       323831|2012-11-25 05:44:37|     2703|                   28|2017-07-26 01:36:08|\n",
      "|  323831|      cynial|2014-05-15 08:09:07|             master|Unirest in PHP: S...|     true|               0|  cynial/unirest-php|         true| 19811504|          PHP|         MIT License|               0|       323831|2014-05-01 19:54:52|      797|                    0|2014-05-15 08:09:07|\n",
      "| 9178045|      Dynera|2014-10-22 20:19:06|             master| Test Repo for class|    false|               0|Dynera/datascienc...|         true| 25602379|         NULL|                NULL|               0|      9178045|2014-10-23 03:18:38|      132|                    0|2014-10-22 20:19:06|\n",
      "| 9178045|      Dynera|2014-10-29 02:06:12|             master|The Leek group gu...|     true|               0|  Dynera/datasharing|         true| 25899802|         NULL|                NULL|               0|      9178045|2013-11-25 16:08:34|      157|                    0|2014-10-28 06:34:25|\n",
      "| 9178045|      Dynera|2014-10-14 19:47:39|             master|                NULL|    false|               0|    Dynera/first_rep|         true| 25223634|         NULL|                NULL|               0|      9178045|2014-10-14 19:50:58|      112|                    0|2014-10-14 19:47:39|\n",
      "|33252592|     pang262|2017-10-31 10:48:51|             master|                NULL|    false|               0|        pang262/Test|         true|108982177|         NULL|                NULL|               0|     33252592|2017-10-31 10:48:52|        0|                    0|2017-10-31 10:48:51|\n",
      "|33252592|     pang262|2017-10-31 14:24:36|             master|                NULL|    false|               0|       pang262/Test3|         true|109006938|         NULL|                NULL|               0|     33252592|2017-10-31 14:24:36|        0|                    0|2017-10-31 14:24:36|\n",
      "| 7906470|PietroMeloni|2015-12-31 22:17:34|             master|                NULL|    false|               0|PietroMeloni/foru...|         true| 48863664|       Python|                NULL|               0|      7906470|2015-12-31 22:42:18|        3|                    0|2015-12-31 22:42:19|\n",
      "| 7906470|PietroMeloni|2017-06-01 15:16:05|             master|                NULL|    false|               0|PietroMeloni/Medi...|         true| 93070888|          C++|GNU General Publi...|               0|      7906470|2017-11-20 16:24:06|     1664|                    0|2017-06-01 15:18:35|\n",
      "+--------+------------+-------------------+-------------------+--------------------+---------+----------------+--------------------+-------------+---------+-------------+--------------------+----------------+-------------+-------------------+---------+---------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "repo_list_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Abstractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format\n",
    "\n",
    "language_popularity_df = (\n",
    "    repo_list_df\n",
    "    .na.drop(subset=[\"repo_language\"])\n",
    "    .withColumn(\"year_month\", date_format(\"repo_created_at\", \"yyyy-MM\"))\n",
    "    .groupBy(\"year_month\", \"repo_language\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"user_count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:======================================================>  (18 + 1) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------+\n",
      "|year_month|   repo_language|user_count|\n",
      "+----------+----------------+----------+\n",
      "|   2013-12|      JavaScript|     17245|\n",
      "|   2015-11|          Python|     20173|\n",
      "|   2014-11|            Ruby|      7054|\n",
      "|   2016-07|           Scala|      1504|\n",
      "|   2017-07|Jupyter Notebook|      7331|\n",
      "|   2017-09|      TypeScript|      8720|\n",
      "|   2018-01|         Gnuplot|        12|\n",
      "|   2015-09|           Scala|      1275|\n",
      "|   2018-03|          Rascal|       108|\n",
      "|   2013-08|           Shell|      1815|\n",
      "|   2017-05|      FreeMarker|        56|\n",
      "|   2011-10|         Haskell|        50|\n",
      "|   2015-04|               D|        41|\n",
      "|   2014-11|        Assembly|       141|\n",
      "|   2014-04|    CoffeeScript|       626|\n",
      "|   2015-01|         FORTRAN|        69|\n",
      "|   2013-04|             CSS|       557|\n",
      "|   2017-12|         Haskell|       669|\n",
      "|   2018-07|          Kotlin|      1478|\n",
      "|   2018-08|      Vim script|        74|\n",
      "+----------+----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "language_popularity_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# # Write data to Azure container\n",
    "# language_popularity_df.write.mode(\"overwrite\").parquet(\n",
    "#     \"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/analytics/language_popularity\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data to ensure data was properly saved\n",
    "test_df = spark.read.parquet(\n",
    "    \"wasbs://kaggle-datasets@matthewleffler1.blob.core.windows.net/analytics/language_popularity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------+\n",
      "|year_month|   repo_language|user_count|\n",
      "+----------+----------------+----------+\n",
      "|   2018-02|      Processing|       331|\n",
      "|   2017-07|      TypeScript|      8111|\n",
      "|   2016-07|              Go|      4328|\n",
      "|   2016-02|      JavaScript|     45462|\n",
      "|   2017-04|     Objective-C|      6531|\n",
      "|   2016-08|          Erlang|       260|\n",
      "|   2011-01|      JavaScript|       982|\n",
      "|   2017-11|           SQLPL|       116|\n",
      "|   2011-01|      Emacs Lisp|        42|\n",
      "|   2017-07|          Rascal|       139|\n",
      "|   2013-08|          Groovy|       148|\n",
      "|   2015-10|            Perl|       780|\n",
      "|   2017-10|              eC|         2|\n",
      "|   2013-12|             Lua|       315|\n",
      "|   2014-10|             ASP|       132|\n",
      "|   2018-08|Jupyter Notebook|      1146|\n",
      "|   2018-07|            Roff|        86|\n",
      "|   2017-11|             SAS|        36|\n",
      "|   2017-07|            XSLT|       290|\n",
      "|   2017-11|   SystemVerilog|        39|\n",
      "+----------+----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year_month: string (nullable = true)\n",
      " |-- repo_language: string (nullable = true)\n",
      " |-- user_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Files to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "\n",
    "# Replace the placeholders with your actual Snowflake credentials\n",
    "conn = snowflake.connector.connect(\n",
    "    user = os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    password = os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    account= os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    warehouse='COMPUTE_WH',\n",
    "    database='BIGDATA_GITHUB',\n",
    "    schema='ANALYTICS',\n",
    "    role='ACCOUNTADMIN'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfullt created stage.\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "url = 'azure://matthewleffler1.blob.core.windows.net/kaggle-datasets/analytics/language_popularity/'\n",
    "\n",
    "try:\n",
    "    cur.execute(\"BEGIN;\")\n",
    "    cur.execute(f\"\"\"\n",
    "        CREATE OR REPLACE STAGE azure_parquet_stage_language_popularity\n",
    "          URL = '{url}'\n",
    "          CREDENTIALS = (\n",
    "            AZURE_SAS_TOKEN = '{os.getenv(\"AZURE_SAS_TOKEN\")}'\n",
    "          )\n",
    "          FILE_FORMAT = (TYPE = PARQUET);\n",
    "        \"\"\")\n",
    "    cur.execute(\"COMMIT;\")\n",
    "    print(f\"Successfullt created stage.\")\n",
    "except Exception as e:\n",
    "    cur.execute(\"ROLLBACK;\")\n",
    "    print(f\"Error creating database object: {e}\")\n",
    "finally:\n",
    "    cur.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully.\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "table_name = \"LANGUAGE_POPULARITY_TABLE\"\n",
    "\n",
    "try:\n",
    "    cur.execute(\"BEGIN;\")\n",
    "    cur.execute(f\"\"\"\n",
    "      CREATE OR REPLACE TABLE {table_name} (\n",
    "          year_month STRING,\n",
    "          repo_language STRING,\n",
    "          user_count BIGINT\n",
    "      );\n",
    "          \"\"\")\n",
    "    cur.execute(\"COMMIT;\")\n",
    "    print(\"Table created successfully.\")\n",
    "except Exception as e:\n",
    "    cur.execute(\"ROLLBACK;\")\n",
    "    print(f\"Error creating database object: {e}\")\n",
    "finally:\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into LANGUAGE_POPULARITY_TABLE successfully.\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    cur.execute(\"BEGIN;\")\n",
    "    cur.execute(f\"\"\"\n",
    "      COPY INTO {table_name}\n",
    "      FROM @azure_parquet_stage_language_popularity\n",
    "      FILE_FORMAT = (TYPE = PARQUET)\n",
    "      MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE\n",
    "      ON_ERROR = CONTINUE;\n",
    "          \"\"\")\n",
    "    cur.execute(\"COMMIT;\")\n",
    "    print(f\"Data loaded into {table_name} successfully.\")\n",
    "except Exception as e:\n",
    "    cur.execute(\"ROLLBACK;\")\n",
    "    print(f\"Error loading data: {e}\")\n",
    "finally:\n",
    "    cur.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (naturalistvenv)",
   "language": "python",
   "name": "naturalistvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
