{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK6CZeX9vMV-",
        "outputId": "4f795b41-3a99-4a74-a752-a18c98f0270a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n",
            "Collecting snowflake-connector-python\n",
            "  Downloading snowflake_connector_python-3.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting boto3>=1.24 (from snowflake-connector-python)\n",
            "  Downloading boto3-1.38.12-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting botocore>=1.24 (from snowflake-connector-python)\n",
            "  Downloading botocore-1.38.12-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.9 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (1.17.1)\n",
            "Requirement already satisfied: cryptography>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (43.0.3)\n",
            "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (24.2.1)\n",
            "Requirement already satisfied: pyjwt<3.0.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (2.10.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (2025.2)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (2.32.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (24.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (2025.4.26)\n",
            "Requirement already satisfied: typing_extensions<5,>=4.3 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (4.13.2)\n",
            "Requirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (3.18.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (2.4.0)\n",
            "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (4.3.7)\n",
            "Collecting tomlkit (from snowflake-connector-python)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.24->snowflake-connector-python)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.13.0,>=0.12.0 (from boto3>=1.24->snowflake-connector-python)\n",
            "  Downloading s3transfer-0.12.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore>=1.24->snowflake-connector-python) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore>=1.24->snowflake-connector-python) (2.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.24->snowflake-connector-python) (1.17.0)\n",
            "Downloading snowflake_connector_python-3.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.38.12-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.38.12-py3-none-any.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.12.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: asn1crypto, tomlkit, jmespath, botocore, s3transfer, boto3, snowflake-connector-python\n",
            "Successfully installed asn1crypto-1.5.1 boto3-1.38.12 botocore-1.38.12 jmespath-1.0.1 s3transfer-0.12.0 snowflake-connector-python-3.15.0 tomlkit-0.13.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install python-dotenv\n",
        "!pip install snowflake-connector-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Initialize variables\n",
        "\n",
        "import snowflake.connector\n",
        "from google.colab import userdata\n",
        "\n",
        "# Replace the placeholders with your actual Snowflake credentials\n",
        "conn = snowflake.connector.connect(\n",
        "    user = userdata.get('SNOWFLAKE_USER'),\n",
        "    password = userdata.get('SNOWFLAKE_PASSWORD'),\n",
        "    account= userdata.get('SNOWFLAKE_ACCOUNT'),\n",
        "    warehouse='COMPUTE_WH',\n",
        "    database='BIGDATA_GITHUB',\n",
        "    schema='RAW',\n",
        "    role='ACCOUNTADMIN'\n",
        ")"
      ],
      "metadata": {
        "id": "eqm2htZ5vSe8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create Snowflake stage for parquet file created by analytics\n",
        "\n",
        "cur = conn.cursor()\n",
        "url = 'azure://matthewleffler1.blob.core.windows.net/kaggle-datasets/clean_data/Influence_Top/'\n",
        "\n",
        "try:\n",
        "    cur.execute(\"BEGIN;\")\n",
        "    cur.execute(f\"\"\"\n",
        "        CREATE OR REPLACE STAGE BIGDATA_GITHUB.ANALYTICS.azure_parquet_stage_Influence_Top\n",
        "          URL = '{url}'\n",
        "          CREDENTIALS = (\n",
        "            AZURE_SAS_TOKEN = '{userdata.get('AZURE_SAS_TOKEN')}'\n",
        "          )\n",
        "          FILE_FORMAT = (TYPE = PARQUET);\n",
        "        \"\"\")\n",
        "    cur.execute(\"COMMIT;\")\n",
        "    print(f\"Successfullt created stage.\")\n",
        "except Exception as e:\n",
        "    cur.execute(\"ROLLBACK;\")\n",
        "    print(f\"Error creating database object: {e}\")\n",
        "finally:\n",
        "    cur.close()"
      ],
      "metadata": {
        "id": "mHFaNuAOvYtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b13a7d-69b8-4a2a-831f-7f149544dddf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfullt created stage.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create Snowflake table defination based on parquet analytics\n",
        "\n",
        "cur = conn.cursor()\n",
        "table_name = \"BIGDATA_GITHUB.ANALYTICS.Influence_Top_100\"\n",
        "\n",
        "try:\n",
        "    cur.execute(\"BEGIN;\")\n",
        "    cur.execute(f\"\"\"\n",
        "      CREATE OR REPLACE TABLE {table_name} (\n",
        "      user_id          BIGINT,\n",
        "      user_login       STRING,\n",
        "      follower_count   BIGINT,\n",
        "      total_stars      BIGINT,\n",
        "      total_commits    BIGINT,\n",
        "      total_forks      BIGINT,\n",
        "      influence_score  FLOAT\n",
        "      );\n",
        "          \"\"\")\n",
        "    cur.execute(\"COMMIT;\")\n",
        "    print(\"Table created successfully.\")\n",
        "except Exception as e:\n",
        "    cur.execute(\"ROLLBACK;\")\n",
        "    print(f\"Error creating database object: {e}\")\n",
        "finally:\n",
        "    cur.close()"
      ],
      "metadata": {
        "id": "GJB9Ob4nvrDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32afa0e2-cecb-4d86-dc12-b83aee543f3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Load data into Snowflake table\n",
        "\n",
        "cur = conn.cursor()\n",
        "\n",
        "try:\n",
        "    cur.execute(\"BEGIN;\")\n",
        "    cur.execute(f\"\"\"\n",
        "      COPY INTO {table_name}\n",
        "      FROM @azure_parquet_stage_Influence_Top\n",
        "      FILE_FORMAT = (TYPE = PARQUET)\n",
        "      MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE\n",
        "      ON_ERROR = CONTINUE;\n",
        "          \"\"\")\n",
        "    cur.execute(\"COMMIT;\")\n",
        "    print(f\"Data loaded into {table_name} successfully.\")\n",
        "except Exception as e:\n",
        "    cur.execute(\"ROLLBACK;\")\n",
        "    print(f\"Error loading data: {e}\")\n",
        "finally:\n",
        "    cur.close()"
      ],
      "metadata": {
        "id": "iJc1gH3DwTEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60608d6b-b705-4189-a1d1-09573b99e025"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded into BIGDATA_GITHUB.ANALYTICS.Influence_Top_100 successfully.\n"
          ]
        }
      ]
    }
  ]
}